{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7f2740b-f160-4046-8ec7-25c6b19252d1",
   "metadata": {},
   "source": [
    "### Importazione librerie utili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbf36cab-d41b-4f3d-8d5f-c115a2d60f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importazione delle librerie utili\n",
    "import pysam\n",
    "from pysam import AlignmentFile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import Bio\n",
    "from Bio import Align\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d46a21-141f-43cb-8a86-b2150c82a912",
   "metadata": {},
   "source": [
    "### Funzioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01481d02-6d60-430e-9559-5d6151f5f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per la pulizia e aggiustamento dei dati ricavati dal file gtf\n",
    "def gtf_to_dataframe(gtf_file_location) :\n",
    "    # Lettura file gtf e salvataggio dataframe\n",
    "    df = pd.read_csv(gtf_file_location, sep = '\\t', header = None)\n",
    "\n",
    "    # Rimpiazzo dei nomi delle colonne\n",
    "    replace_dict = {0 : 'reference', 1 : 'source', 2 : 'feature', 3 : 'start',\n",
    "                4 : 'end', 5 : 'score', 6 : 'strand', 7 : 'frame', 8 : 'attributes'}\n",
    "    df.rename(columns = replace_dict, inplace = True)\n",
    "    \n",
    "    # Rimozione colonne non utili\n",
    "    df.drop(['source', 'score'], axis = 1, inplace = True)\n",
    "\n",
    "    # Creazione colonne di id trascritto e nome gene + rimozione colonna attributi\n",
    "    df['transcript_id'] = df['attributes'].apply(lambda x : re.search(r'transcript_id\\s+\"(.+?)\";', x).group(1))\n",
    "    df['gene'] = df['attributes'].apply(lambda x : re.search(r'gene_id\\s+\"(.+?)\";', x).group(1))\n",
    "    df.drop('attributes', axis = 1, inplace = True)\n",
    "\n",
    "    # Creazione colonna che contiene la lunghezza\n",
    "    df['length'] = df['end'] - df['start'] + 1\n",
    "\n",
    "    # Reindicizzazione delle colonne del df\n",
    "    df = df.reindex(columns = ['reference', 'feature', 'start', 'end',\n",
    "                      'length', 'strand', 'frame', 'gene', 'transcript_id'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aad6e4a5-7fff-4c38-968a-6cb6478b888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per creare il file contenente i reads spliced\n",
    "def get_spliced_reads_file(all_alignments, output_file):\n",
    "\n",
    "    # Apro il file e lo svuoto (\"reset\")\n",
    "    with open(output_file, \"w\") as f:\n",
    "        pass \n",
    "    \n",
    "    # Recuperare i reads spliced cercando la N nelle cigar string\n",
    "    all_spliced_reads = list(set([alignment for alignment in all_alignments if 'N' in alignment.cigarstring]))\n",
    "\n",
    "    # Costruzione del file\n",
    "    with open(output_file, \"w\") as fastq_file:\n",
    "        for read in all_spliced_reads:\n",
    "            read_id = read.query_name\n",
    "            read_sequence = read.query_sequence\n",
    "\n",
    "            if read.query_qualities == None:\n",
    "                # Viene salvata una quality string di default \n",
    "                read_quality_string = \"I\" * len(read_sequence)\n",
    "            else:\n",
    "                read_quality_string = read.query_qualities\n",
    "\n",
    "            # Scrittura sul file\n",
    "            fastq_file.write(f'@'+read_id+'\\n'+read_sequence+'\\n'+'+\\n'+read_quality_string+'\\n')\n",
    "\n",
    "    # Ritorno la lista di tutti i read spliced\n",
    "    return all_spliced_reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fb0eebb-e0f0-4499-b6c5-0e048b249cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcripts(df):\n",
    "    # Viene quindi trovato lo start e l'end per ogni trascritto e il suo gene di appartenenza\n",
    "    transcript_dict = {}\n",
    "    \n",
    "    # Scorro sui geni\n",
    "    for gene in set(df['gene']):\n",
    "        \n",
    "        # Maschera per prendere soltanto trascritti associati al gene e che sono esoni\n",
    "        mask = (df.gene == gene) & (df.feature == 'exon')\n",
    "        \n",
    "        # Scorro sui trascritti per il gene\n",
    "        for transcript_id in df[mask].groupby('transcript_id').groups:\n",
    "    \n",
    "            # Trovo tutti gli esoni associati al trascritto\n",
    "            index_list = df[mask].groupby('transcript_id').groups[transcript_id]\n",
    "            exon_list_sorted = sorted(zip(df.loc[index_list]['start'], df.loc[index_list]['end']))\n",
    "            \n",
    "            # Salvo la entry trascritto : (gene, start_trascritto, end_trascritto) in trascript_list\n",
    "            transcript_dict[transcript_id] = (gene, exon_list_sorted[0][0], exon_list_sorted[-1][1])\n",
    "\n",
    "    return transcript_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c89368f5-58f8-456f-92df-7409e415796e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_associated_transcripts(transcript_dict, all_alignments):\n",
    "    # Dizionario read : trascritto da cui è stato sequenziato\n",
    "    associated_transcript_dict = {}\n",
    "    \n",
    "    for alignment in all_alignments:\n",
    "        for transcript_key in transcript_dict:\n",
    "            if ((transcript_dict[transcript_key][1] <= alignment.reference_start <= transcript_dict[transcript_key][2]) &\n",
    "                (transcript_dict[transcript_key][1] <= alignment.reference_end <= transcript_dict[transcript_key][2])):\n",
    "                associated_transcript_dict[alignment.query_name] = (transcript_key, transcript_dict[transcript_key][0])\n",
    "\n",
    "    return associated_transcript_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0956c6e-2763-4825-8e83-01825aab7e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequentied_transcript(associated_transcript_dict):\n",
    "    # Risulta un unico elemento cioè il trascritto da cui sono stati sequenziati tutti i read\n",
    "    from_transcript = list(set(associated_transcript_dict.values()))[0]\n",
    "\n",
    "    return from_transcript[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "069398bb-fbb5-4757-a6ac-a96c9d266f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gene_from_transcript(sequentied_transcript, transcript_dict):\n",
    "    return transcript_dict[sequentied_transcript][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "437d7908-2bcc-4d2d-bcdc-2ba9921c6366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequentied_transcript_subprocess(bam_file_location, gtf_file_location, output_file):\n",
    "    # Comando unico per trovare da quali trascritti sono stati sequenziati i read\n",
    "    cmd = [\n",
    "        \"htseq-count\", \"-f\", \"bam\", \"-r\", \"pos\", \"-s\", \"no\",\n",
    "        \"-i\", \"transcript_id\",\n",
    "        bam_file_location, gtf_file_location\n",
    "    ]\n",
    "\n",
    "    # Scrittura file associazioni trascritto : numero read sequenziati da esso\n",
    "    with open(output_file, \"w\") as out_file:\n",
    "        subprocess.run(cmd, stdout=out_file)\n",
    "\n",
    "    # Creo il dizionario per verificare i risultati del comando unico\n",
    "    read_transcript_association_dict = {}\n",
    "\n",
    "    # Leggo il file generato dal comando\n",
    "    with open(output_file, \"r\") as file:\n",
    "        for line in file:\n",
    "            key, value = line.strip().split(\"\\t\")  # Divide sulla tabulazione\n",
    "            read_transcript_association_dict[key] = int(value)  # Converte il valore in intero\n",
    "    \n",
    "    # Filtrare solo i record con value > 0\n",
    "    read_transcript_association_dict = {key: value for key, value in read_transcript_association_dict.items() if value > 0}\n",
    "    \n",
    "    return read_transcript_association_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d289651f-3a75-4070-b6bd-1ecdcf97a43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequentied_transcript_file(sequentied_transcript, transcript_associated_gene, output_file):\n",
    "    with open(output_file, \"w\") :\n",
    "            pass\n",
    "    \n",
    "    # Scrive ogni coppia (chiave, valore) su una riga del file\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(f'SEQUENTIED TRANSCRIPT: {sequentied_transcript}\\n')\n",
    "        f.write(f'ASSOCIATED GENE: {transcript_associated_gene}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bd923b1-dc79-4d04-a9a7-6899026cc70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_intron(all_introns):\n",
    "    # Trova il valore di copertura massimo\n",
    "    max_cover = max(all_introns.values())\n",
    "    \n",
    "    # Trova tutti gli introni con copertura massima\n",
    "    max_introns = [(interval, value) for (interval, value) in all_introns.items() if value == max_cover] \n",
    "\n",
    "    # Prendo come introne da \"studiare\" il primo della lista\n",
    "    best_intron = max_introns[0]\n",
    "\n",
    "    return best_intron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6891cfb-4af7-453f-a8c8-ef904be6839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_introns_support_file(all_introns, best_intron, output_file):\n",
    "    with open(output_file, \"w\") :\n",
    "            pass\n",
    "    \n",
    "    # Scrive ogni coppia (chiave, valore) su una riga del file\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(f'INTRONS: \\n\\n')\n",
    "        \n",
    "        for locus, count in all_introns.items():\n",
    "            f.write(f'- {locus} : {count}\\n')\n",
    "\n",
    "        f.write(f'\\nMax support intron -> {best_intron[0]} with support = {best_intron[1]} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1db30335-48c8-4ae6-9f1b-e3d728ac170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alignment_file(intron_aligned_reads, reference, output_file):\n",
    "    with open(output_file, \"w\") :\n",
    "        pass\n",
    "    \n",
    "    with open(output_file, \"w\") as f:\n",
    "\n",
    "        f.write(f'READS ALIGNED TO BEST INTRON: \\n\\n')\n",
    "        \n",
    "        for read in intron_aligned_reads:\n",
    "            # Salvo info del read\n",
    "            read_seq = read.seq\n",
    "            read_cigar = read.cigarstring\n",
    "            read_blocks = read.get_blocks() # Salva lista di (start, end) delle sottostringhe allineate e senza gap del read \n",
    "        \n",
    "            # Lista di ogni carattere del read con: posizione sulla reference e operatore associato\n",
    "            aligned_pairs = read.get_aligned_pairs(matches_only=False, with_seq=True, with_cigar=True)\n",
    "        \n",
    "            f.write(f'{read.query_name} -------------------------------------------------\\n\\n')\n",
    "            f.write(f'READ INFO:\\n\\n')\n",
    "            f.write(f'Read sequence -> {read_seq}\\n')\n",
    "            f.write(f'Cigar string -> {read_cigar}\\n\\n\\n')\n",
    "            f.write(f'ALIGNMENT: \\n\\n')\n",
    "            \n",
    "            # Scorro sui blocchi del read in modo da generare un allineamento testuale per ciascuno di essi\n",
    "            for i, (block_start, block_end) in enumerate(read_blocks):\n",
    "                query = ''\n",
    "            \n",
    "                # Scorro sulle aligned_pairs per costruire la query\n",
    "                for (_, ref_position, char, _) in aligned_pairs:\n",
    "                    # pair[1] contiene la posizione sulla reference, controllo che non sia None \n",
    "                    if (ref_position != None):\n",
    "            \n",
    "                        # Se il carattere fa parte del blocco considerato viene aggiunto alla query\n",
    "                        if ((ref_position >= block_start) & (ref_position < block_end)):\n",
    "                            query = query + char\n",
    "            \n",
    "                # Rendo la query uppercase dato che ho notato che ci sono dei caratteri minuscoli\n",
    "                query = query.upper()\n",
    "            \n",
    "                # Recupero la reference relativa alle posizioni del blocco\n",
    "                reference_seq = reference[block_start : block_end]\n",
    "        \n",
    "                # Eseguo l'allineamento\n",
    "                result_alignments = aligner.align(reference_seq, query)\n",
    "        \n",
    "                # Recupero l'allineamento con score maggiore\n",
    "                best_alignment = sorted(result_alignments)[0]\n",
    "        \n",
    "                # Stampo allineamento\n",
    "                f.write(f'{best_alignment}\\n')\n",
    "        \n",
    "                if i != len(read_blocks) - 1:\n",
    "                    f.write(f'************************ ... INTRON ... ************************\\n\\n')\n",
    "        \n",
    "            f.write(f'\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8bdd7c3-2d84-4fbb-b5e4-78a3b0e624f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_report(sequentied_transcript_file, introns_file, alignment_file, report_file):\n",
    "    with open(report_file, \"w\") as out_f:\n",
    "        for file in [sequentied_transcript_file, introns_file, alignment_file]:\n",
    "            with open(file, \"r\") as in_f:\n",
    "                out_f.write(in_f.read() + \"\\n\\n\\n###################################################################################\\n\\n\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4835b5bb-1394-4a06-b7bd-eed406879574",
   "metadata": {},
   "source": [
    "### Parametri di input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1a27db1-1ad0-4ed6-ae4b-cbe1c7f40774",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf_file_location = './input_files/annotation_one_tr_chr8.gtf'\n",
    "bam_file_location = './input_files/sample-chr8.bam'\n",
    "fasta_file_location = './input_files/Homo_sapiens.GRCh38.dna.chromosome.8.fa'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afef877d-c354-43df-88fe-4dd3ba2242fc",
   "metadata": {},
   "source": [
    "### File di output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32c6931f-0281-46ae-b743-8ce880e9dca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spliced_read_file = \"./output_files/spliced_reads.fastq\"\n",
    "output_counts_transcript = \"./output_files/output_counts_transcript.txt\"\n",
    "sequentied_transcript_file = \"./output_files/sequentied_transcript_file.txt\"\n",
    "introns_file = \"./output_files/introns_file.txt\"\n",
    "alignment_file = \"./output_files/alignment_output.txt\"\n",
    "report_file = \"./output_files/report.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f30be67-72c4-4831-9912-7e929e7ead5c",
   "metadata": {},
   "source": [
    "### Codice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a52c13ae-34c9-4a01-996f-2e1bb1043c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gtf_to_dataframe(gtf_file_location)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0ca3a54-0636-4364-94ad-832248b1e32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lettura del file BAM\n",
    "pysam.index(bam_file_location)\n",
    "bam_file = AlignmentFile(bam_file_location, 'rb')\n",
    "\n",
    "#Lettura degli allineamenti\n",
    "all_alignments = list(bam_file.fetch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17748132-5358-49f0-b453-eaae399c76c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione del file contenente i reads spliced e ritorna lista dei reads spliced\n",
    "spliced_reads = get_spliced_reads_file(all_alignments, spliced_read_file)\n",
    "#spliced_reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f136f3e3-f43b-48fd-9f92-fdda21ebe78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viene quindi trovato lo start e l'end per ogni trascritto e il suo gene di appartenenza\n",
    "transcript_dict = get_transcripts(df)\n",
    "#transcript_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc21e2b2-eb38-4b95-8f08-a0ae8fcf8416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dizionario read : trascritto da cui è stato sequenziato\n",
    "associated_transcript_dict = get_associated_transcripts(transcript_dict, all_alignments)\n",
    "#associated_transcript_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fd7b691-beea-48d8-9bea-7f32d0cecfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvo il trascritto da cui sono stati sequenziati i read\n",
    "sequentied_transcript = get_sequentied_transcript(associated_transcript_dict)\n",
    "#sequentied_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0105ac4-60e4-4054-b96e-7929bb9f12fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvo il gene associato al trascritto da cui sono stati sequenziati i read\n",
    "transcript_associated_gene = get_gene_from_transcript(sequentied_transcript, transcript_dict)\n",
    "#transcript_associated_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41e4ae1c-e298-4866-b17f-82b19e230a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11533 GFF lines processed.\n",
      "522 alignment record pairs processed.\n"
     ]
    }
   ],
   "source": [
    "read_transcript_association_dict = get_sequentied_transcript_subprocess(bam_file_location, gtf_file_location, output_counts_transcript)\n",
    "#read_transcript_association_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5819792a-a290-4680-89c7-597aac3717f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cerco gli introni del trascritto e numero di reads che supportano l'introne\n",
    "all_introns = bam_file.find_introns(bam_file.fetch())\n",
    "#all_introns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74d71096-7cc6-41b1-8925-99d2b52e4717",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_intron = get_best_intron(all_introns)\n",
    "#best_intron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "488cd7d6-ec58-4ff9-912d-b71d7d93c104",
   "metadata": {},
   "outputs": [],
   "source": [
    "intron_start, intron_end = best_intron[0][0], best_intron[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a82507f-ebde-49b8-9956-4b76b8ec7814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lettura del file FASTA indicizzato\n",
    "fasta = pysam.FastaFile(fasta_file_location)\n",
    "\n",
    "# Specifica il cromosoma e le coordinate (0-based)\n",
    "chrom = fasta.references[0]\n",
    "\n",
    "# Estrarre la sequenza\n",
    "reference = fasta.fetch(chrom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de2a86b5-9c78-48b2-9db9-64c9597c3ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvo le posizioni di inizio e fine del trascritto sequenziato\n",
    "transcript_position = (transcript_dict[sequentied_transcript][1], transcript_dict[sequentied_transcript][2])\n",
    "transcript_start, transcript_end = transcript_position[0], transcript_position[1]\n",
    "#print(transcript_start, transcript_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e56299b-90e0-42c2-94a8-182a91e8ec52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cerco i reads allineati all'introne\n",
    "intron_aligned_reads = [read for read in spliced_reads if ((read.reference_start <= intron_start) & (read.reference_end >= intron_end))]\n",
    "#intron_aligned_reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56b165f6-d73f-42c0-a02a-c866b65b539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligner = Align.PairwiseAligner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fca5e23f-d782-45ae-b7e4-c5148d484a83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_sequentied_transcript_file(sequentied_transcript, transcript_associated_gene, sequentied_transcript_file)\n",
    "get_introns_support_file(all_introns, best_intron, introns_file)\n",
    "get_alignment_file(intron_aligned_reads, reference, alignment_file)\n",
    "\n",
    "# Scrittura del report \n",
    "write_report(sequentied_transcript_file, introns_file, alignment_file, report_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
